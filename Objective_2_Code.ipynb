{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "# Install NLTK stopwords if needed\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel(\"/content/What changes, if any, would you suggest for the academic preparation of this student.xlsx\")\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'_x[0-9a-fA-F]{4}_', '', text)  # Remove patterns like _x000D_\n",
        "    tokens = text.split()  # Tokenize text\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stop words\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predefined stop words and additional domain-specific stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stop_words = {\n",
        "    \"student\", \"work\", \"prepared\", \"suggestions\", \"would\", \"changes\", \"academic\", \"preparation\",\n",
        "    \"to\", \"be\", \"for\", \"the\", \"of\", \"this\", \"position\", \"from\", \"a\", \"it\", \"could\", \"make\", \"sure\",\n",
        "    \"that\", \"real\", \"world\", \"are\", \"in\", \"with\", \"drexel\", \"is\", \"able\", \"experiences\", \"co\", \"ops\",\n",
        "    \"help\", \"only\", \"but\", \"also\", \"have\", \"been\", \"and\", \"will\", \"on\", \"right\",\n",
        "    \"great\", \"him\", \"well\", \"into\", \"future\", \"maybe\", \"more\", \"oriented\", \"food\", \"i\", \"think\",\n",
        "    \"based\", \"students\", \"better\", \"at\", \"really\", \"these\", \"how\", \"use\", \"areas\", \"or\", \"courses\", \"other\", \"like\", \"any\", \"some\", \"where\", \"you\",\n",
        "    \"learn\", \"about\", \"different\", \"etc\", \"has\", \"very\", \"good\", \"can\", \"continue\", \"if\", \"she\",\n",
        "    \"job\", \"such\", \"as\", \"when\", \"he\", \"academic\", \"much\", \"role\", \"learned\", \"hard\", \"overall\",\n",
        "    \"an\", \"take\", \"improve\", \"her\", \"handle\", \"focus\", \"tools\", \"they\", \"their\", \"prior\",\n",
        "    \"op\", \"most\", \"important\", \"our\", \"get\", \"so\", \"many\", \"people\", \"professional\", \"what\", \"we\",\n",
        "    \"no\", \"strong\", \"here\", \"had\", \"all\", \"tasks\", \"changes\", \"helpful\",\n",
        "    \"given\", \"up\", \"beneficial\", \"out\", \"email\", \"was\", \"don\", \"t\", \"there\", \"his\", \"were\", \"s\",\n",
        "    \"exposure\", \"academically\", \"yes\", \"understanding\", \"not\", \"school\", \"which\", \"further\",\n",
        "    \"needs\", \"training\", \"path\", \"my\", \"specific\", \"needed\", \"them\", \"industry\",\n",
        "    \"understand\", \"related\", \"however\", \"prepare\", \"interest\", \"suggest\", \"major\", \"than\", \"office\",\n",
        "    \"benefit\", \"every\", \"team\", \"recommend\", \"studies\", \"vs\", \"nothing\", \"within\", \"n\", \"_x000d_\",\n",
        "    \"believe\", \"during\", \"need\", \"social\", \"media\", \"should\",\n",
        "    \"opportunities\", \"working\", \"career\", \"suggestion\", \"background\",\n",
        "    \"taking\", \"did\", \"always\", \"new\", \"something\", \"those\", \"development\", \"even\", \"d\", \"skill\",\n",
        "    \"over\", \"see\", \"workplace\", \"your\", \"do\", \"already\", \"e\", \"day\", \"by\", \"executive\", \"just\",\n",
        "    \"who\", \"group\", \"may\", \"level\", \"technologies\", \"none\", \"no\", \"nan\", \"nothing\", \"excellent\",\n",
        "}\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "# Synonym library\n",
        "synonym_library = {\n",
        "    \"accounting\": [\"accounting\", \"basic accounting\", \"accounting basics\", \"financial accounting\", \"managerial accounting\",\n",
        "                   \"bookkeeping\", \"cash flows\", \"invoice\", \"accounting introduction\", \"internal audit\"],\n",
        "    \"finance\": [\"finance\", \"financial\", \"intro to finance\", \"basics of finance\", \"financial planning\", \"investment management\",\n",
        "                \"corporate finance\", \"insurance\", \"financial reporting\", \"financial analysis\",\n",
        "                \"portfolio rebalancing\", \"portfolio management\", \"financial markets\"],\n",
        "    \"statistics\": [\"statistics\", \"basic statistics\", \"intro to stats\", \"statistical methods\", \"data statistics\", \"applied statistics\"],\n",
        "    \"python\": [\"python\", \"python programming\", \"python coding\", \"python scripting\"],\n",
        "    \"sql\": [\"sql\", \"structured query language\", \"sql programming\", \"database querying\"],\n",
        "    \"data_analysis\": [\"data analysis\", \"analyzing data\", \"data analytics\", \"data insights\"],\n",
        "    \"business_analytics\": [\"business analytics\", \"analytics for business\", \"business data analytics\", \"business intelligence\", \"projections\", \"projection\", \"kpis\", \"key performance indicators\"],\n",
        "    \"automation\": [\"automation\", \"intelligent automation tools\", \"workflow automation\", \"process automation\"],\n",
        "    \"leadership\": [\"leadership\", \"executive leadership\", \"project leadership\", \"team leadership\", \"organizational leadership\"],\n",
        "    \"tax\": [\"tax\", \"tax accounting\", \"tax planning\", \"tax strategies\"],\n",
        "    \"public_speaking\": [\"public speaking\", \"presentation skills\", \"oral communication\", \"speech delivery\", \"storytelling\"],\n",
        "    \"excel\": [\"excel\", \"microsoft excel\", \"advanced excel skills\", \"pivot tables in excel\", \"vlookup\", \"data modeling\", \"spreadsheet\"],\n",
        "    \"powerpoint\": [\"powerpoint\", \"microsoft powerpoint\", \"presentation design\", \"slides creation\"],\n",
        "    \"marketing\": [\"marketing\", \"digital marketing\", \"marketing strategies\", \"social media marketing\", \"advertising\", \"seo\", \"content marketing\"],\n",
        "    \"project_management\": [\"project management\", \"agile project management\", \"waterfall project management\", \"pmp\", \"scrum\"],\n",
        "    \"critical_thinking\": [\"critical thinking\", \"problem solving\", \"analytical thinking\", \"decision making\"],\n",
        "    \"data_visualization\": [\"data visualization\", \"chart creation\", \"dashboard creation\", \"data storytelling\", \"tableau\", \"power bi\"],\n",
        "    \"programming\": [\"programming\", \"coding\", \"software development\", \"scripting\"],\n",
        "    \"time_management\": [\"time management\", \"productivity skills\", \"scheduling\", \"prioritization\"],\n",
        "    \"crm\": [\"crm\", \"customer relationship management\", \"salesforce\", \"hubspot\", \"zoho crm\"],\n",
        "    \"ms_office\": [\"ms office\", \"microsoft office\", \"word\", \"outlook\"],\n",
        "    \"networking\": [\"networking\", \"professional networking\", \"relationship building\", \"linkedin\"],\n",
        "    \"entrepreneurship\": [\"entrepreneurship\", \"startup skills\", \"venture creation\", \"business innovation\"],\n",
        "    \"customer_service\": [\"customer service\", \"client relations\", \"service management\"],\n",
        "    \"supply_chain\": [\"supply chain\", \"logistics\", \"inventory management\", \"procurement\", \"supply chain analytics\"],\n",
        "    \"hr_management\": [\"hr management\", \"human resources\", \"recruitment\", \"talent management\", \"employee relations\"],\n",
        "    \"cybersecurity\": [\"cybersecurity\", \"information security\", \"network security\", \"data security\", \"ethical hacking\"],\n",
        "    \"soft_skills\": [\"speaking\", \"speak\", \"technical communication\", \"communication\", \"business communication\", \"written communication\", \"verbal communication\", \"busi-comm\", \"business communications\"],\n",
        "    \"presentation\": [\"present\",  \"presentation\", \"presentations\", \"presenting\"],\n",
        "    \"sales\": [\"sales\", \"selling\", \"sale\"],\n",
        "    \"technical_skills\": [\"technical skills\", \"reporting\", \"tracking\", \"trading\", \"planning\", \"forecasting\", \"graphic design\"],\n",
        "    \"syst_anal\": [\"systems analysis\", \"system analysis\"],\n",
        "    \"business\": [\"business\"],\n",
        "    \"hospitality\": [\"beverage\", \"beverages\"],\n",
        "    \"writing_skills\": [\"email\", \"emails\", \"e-mail\", \"e mail\", \"e-mails\", \"writing\", \"written\"],\n",
        "    \"prioritization\": [\"prioritize\", \"prioritization\", \"priority\"],\n",
        "    \"partcipation\": [\"involved\", \"involve\", \"engagement\", \"engage\", \"engaging\"],\n",
        "    \"busi-manag\": [\"business management\"],\n",
        "    \"org-manag\": [\"organizational management\"],\n",
        "    \"data science\": [\"data science\"],\n",
        "    \"data_domain\": [\"database knoweldge\", \"cloud based software\"],\n",
        "    \"data_manipulation\": [\"data manipulations\", \"data manipulation\"],\n",
        "    \"software\": [\"software\"],\n",
        "    \"computer_skills\": [\"computer skills\"],\n",
        "\n",
        "    }\n",
        "\n",
        "# Match keywords from the synonym library\n",
        "def match_keywords(text, synonym_lib):\n",
        "    matched_courses = []\n",
        "    for course, keywords in synonym_lib.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                matched_courses.append(course)\n",
        "    return matched_courses\n",
        "\n",
        "# Function to remove repetitive words while preserving the order\n",
        "def remove_repeated_words(text_list):\n",
        "    \"\"\"\n",
        "    Removes repeated words from a list of words while preserving the order.\n",
        "\n",
        "    Args:\n",
        "        text_list (list): A list of words (strings).\n",
        "\n",
        "    Returns:\n",
        "        str: A string containing the distinct words separated by spaces.\n",
        "    \"\"\"\n",
        "    seen = set()\n",
        "    distinct_words = []\n",
        "    for word in text_list:  # Iterate through the list of words directly\n",
        "        if word not in seen:\n",
        "            seen.add(word)\n",
        "            distinct_words.append(word)\n",
        "    return ' '.join(distinct_words)\n",
        "\n",
        "# Analyze text for relevant courses\n",
        "def analyze_text(df, synonym_lib):\n",
        "    df['Cleaned_Text'] = df['What changes, if any, would you suggest for the academic preparation of this student?'].apply(preprocess_text)\n",
        "    df['Matched_Courses'] = df['Cleaned_Text'].apply(lambda x: match_keywords(x, synonym_lib))\n",
        "    return df\n",
        "\n",
        "# Process the data\n",
        "df = analyze_text(df, synonym_library)\n",
        "\n",
        "# Apply the function to remove repeated words in the 'Matched_Courses' column\n",
        "df['Distinct_Response'] = df['Matched_Courses'].apply(remove_repeated_words)\n",
        "\n",
        "# Explode matched courses into separate rows for Power BI\n",
        "df_exploded = df.explode('Matched_Courses')\n",
        "\n",
        "# Match keywords from the synonym library\n",
        "def match_keywords(text, synonym_lib):\n",
        "    matched_courses = []\n",
        "    for course, keywords in synonym_lib.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                matched_courses.append(course)\n",
        "    return matched_courses\n",
        "\n",
        "# Create binary columns for synonym library matches\n",
        "def add_binary_columns(df, synonym_lib):\n",
        "    for course, keywords in synonym_lib.items():\n",
        "        df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
        "    return df\n",
        "\n",
        "# Add \"Others\" column\n",
        "def add_others_column(df, synonym_lib):\n",
        "    keyword_columns = list(synonym_lib.keys())\n",
        "    # Add the \"Others\" column\n",
        "    df['Others'] = df[keyword_columns].sum(axis=1).apply(lambda x: 1 if x == 0 else 0)\n",
        "    return df\n",
        "\n",
        "# Analyze text for relevant courses and add binary columns\n",
        "def analyze_text_and_add_binaries(df, synonym_lib):\n",
        "    # Preprocess and find matches\n",
        "    df['Cleaned_Text'] = df['What changes, if any, would you suggest for the academic preparation of this student?'].apply(preprocess_text)\n",
        "    df['Matched_Courses'] = df['Cleaned_Text'].apply(lambda x: match_keywords(x, synonym_lib))\n",
        "    df\n",
        "    # Add binary columns for all synonym library categories\n",
        "    df = add_binary_columns(df, synonym_lib)\n",
        "\n",
        "    # Add \"Others\" column\n",
        "    df = add_others_column(df, synonym_lib)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Process the data\n",
        "df = analyze_text_and_add_binaries(df, synonym_library)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "output_path = \"processed_suggestions_with_binary_columns_and_others.xlsx\"\n",
        "df.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"Processing completed and results saved with binary columns and 'Others' column!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RJlIHmP87fCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537ae87e-4901-412f-c669-32078c376e4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing completed and results saved with binary columns and 'Others' column!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "# Install NLTK stopwords if needed\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel(\"/content/How did your classroom activities prepare you for co-op If they didn’t, how were you prepared for co-op.xlsx\")\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'_x[0-9a-fA-F]{4}_', '', text)  # Remove patterns like _x000D_\n",
        "    tokens = text.split()  # Tokenize text\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stop words\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Define negative keywords for classification\n",
        "negative_keywords = [\n",
        "    \"not prepared\", \"not really prepared\", \"wasn’t prepared\", \"did not prepare\",\n",
        "    \"wasn't prepped\", \"didn't prep\", \"did not prep\", \"not prepped\", \"nothing\",\n",
        "    \"no preparation\", \"not ready\", \"didn’t prepare\", \"didn't prepare\", \"did not\", \"didn't\", \"not really\",\n",
        "]\n",
        "\n",
        "# funtion to classify responses\n",
        "def classify_response(response):\n",
        "    \"\"\"\n",
        "    Classifies a response as \"nothing\" if it contains any negative keywords,\n",
        "    otherwise classifies as \"prepared\".\n",
        "\n",
        "    Args:\n",
        "        response (str): The text response to classify.\n",
        "\n",
        "    Returns:\n",
        "        str: \"nothing\" if negative keywords are found, \"prepared\" otherwise.\n",
        "    \"\"\"\n",
        "    # Check if the response is a string before converting to lowercase\n",
        "    if isinstance(response, str):\n",
        "        response_lower = response.lower()  # Convert to lowercase for case-insensitive matching\n",
        "        for keyword in negative_keywords:\n",
        "            if keyword in response_lower:\n",
        "                return \"not prepared\"  # Match found, classify as \"nothing\"\n",
        "    #     return \"prepared\"  # No match found, classify as \"prepared\"\n",
        "    # else:\n",
        "    #     # Handle non-string responses (e.g., NaN) - return \"prepared\" or other appropriate value\n",
        "    #     return \"prepared\"\n",
        "\n",
        "# Predefined stop words and additional domain-specific stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stop_words = {\n",
        "    'i', 'me', 'my', 'we', 'our', 'ours', 'you', 'your', 'yours',\n",
        "    'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their',\n",
        "    'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',\n",
        "    'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
        "    'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
        "    'into', 'through', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n",
        "    'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all',\n",
        "    'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'same',\n",
        "    'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
        "}\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "# Synonym library (add the full library here)\n",
        "synonym_library = {\n",
        "    \"acct116\": [\"acct 116\", \"acct-116\", \"accounting 116\", \"managerial accounting\"],\n",
        "    \"acct115\": [\"acct 115\", \"acct-115\", \"accounting 115\", \"financial accounting\"],\n",
        "    \"acct110\": [\"acct 110\", \"acct-110\", \"accounting 110\", \"accounting for professionals\"],\n",
        "    \"acct321\": [\"acct 321\", \"acct-321\", \"accounting321\", \"accounting 321\", \"financial reporting i\"],\n",
        "    \"acct323\": [\"acct 323\", \"acct-323\", \"accounting323\", \"accounting 323\", \"financial reporting iii\"],\n",
        "    \"acct329\": [\"acct 329\", \"acct-329\", \"accounting329\", \"accounting 329\", \"advanced accounting\"],\n",
        "    \"acct341\": [\"acct 341\", \"acct-341\", \"accounting341\", \"accounting 341\", \"principles auditing\"],\n",
        "    \"acct510\": [\"acct 510\", \"acct-510\", \"accounting510\", \"accounting 510\", \"essentials financial reporting\"],\n",
        "    \"acct600\": [\"acct 600\", \"acct-600\", \"accounting600\", \"accounting 600\", \"accounting analysis & theory\"],\n",
        "    \"acct606\": [\"acct 606\", \"acct-606\", \"accounting606\", \"accounting 606\", \"current issues accounting profession\"],\n",
        "    \"acct622\": [\"acct 622\", \"acct-622\", \"accounting622\", \"accounting 622\", \"advanced financial accounting\"],\n",
        "    \"acct912\": [\"acct 912\", \"acct-912\", \"accounting912\", \"accounting 912\", \"applied research methods accounting\"],\n",
        "    \"acct998\": [\"acct 998\", \"acct-998\", \"accounting998\", \"accounting 998\", \"dissertation research accounting\"],\n",
        "    \"stat201\": [\"stat 201\", \"stat-201\", \"statistics201\", \"statistics 201\", \"introduction business statistics\", \"business statistics i\"],\n",
        "    \"stat202\": [\"stat 202\", \"stat-202\", \"statistics202\", \"statistics 202\", \"business statistics ii\"],\n",
        "    \"stat205\": [\"stat 205\", \"stat-205\", \"statistics205\", \"statistics 205\", \"statistical inference i\"],\n",
        "    \"stat331\": [\"stat 331\", \"stat-331\", \"statistics331\", \"statistics 331\", \"introduction data mining business\"],\n",
        "    \"stat610\": [\"stat 610\", \"stat-610\", \"statistics610\", \"statistics 610\", \"statistics business analytics\"],\n",
        "    \"stat628\": [\"stat 628\", \"stat-628\", \"statistics628\", \"statistics 628\", \"applied regression analysis\"],\n",
        "    \"stat931\": [\"stat 931\", \"stat-931\", \"statistics931\", \"statistics 931\", \"statistics economics\"],\n",
        "    \"stat932\": [\"stat 932\", \"stat-932\", \"statistics932\", \"statistics 932\", \"statistics behavioral science\"],\n",
        "    \"fin301\": [\"fin 301\", \"fin-301\", \"finance301\", \"finance 301\", \"introduction finance\"],\n",
        "    \"fin302\": [\"fin 302\", \"fin-302\", \"finance302\", \"finance 302\", \"intermediate corporate finance\"],\n",
        "    \"fin321\": [\"fin 321\", \"fin-321\", \"finance321\", \"finance 321\", \"investment securities & markets\"],\n",
        "    \"fin323\": [\"fin 323\", \"fin-323\", \"finance323\", \"finance 323\", \"risk management\"],\n",
        "    \"fin325\": [\"fin 325\", \"fin-325\", \"finance325\", \"finance 325\", \"financial institutions and markets\"],\n",
        "    \"fin332\": [\"fin 332\", \"fin-332\", \"finance332\", \"finance 332\", \"investment analysis\"],\n",
        "    \"fin335\": [\"fin 335\", \"fin-335\", \"finance335\", \"finance 335\", \"entrepreneurial finance\"],\n",
        "    \"fin341\": [\"fin 341\", \"fin-341\", \"finance341\", \"finance 341\", \"applied portfolio management\"],\n",
        "    \"fin345\": [\"fin 345\", \"fin-345\", \"finance345\", \"finance 345\", \"mergers & acquisitions\"],\n",
        "    \"fin346\": [\"fin 346\", \"fin-346\", \"finance346\", \"finance 346\", \"global financial management\"],\n",
        "    \"fin601\": [\"fin 601\", \"fin-601\", \"finance601\", \"finance 601\", \"corporate financial management\"],\n",
        "    \"fin605\": [\"fin 605\", \"fin-605\", \"finance605\", \"finance 605\", \"business valuation\"],\n",
        "    \"fin624\": [\"fin 624\", \"fin-624\", \"finance624\", \"finance 624\", \"risk management financial professionals\"],\n",
        "    \"blaw\": [\"business law\"],\n",
        "    \"blaw101\": [\"blaw 101\", \"blaw-101\", \"businesslaw101\", \"business law 101\"],\n",
        "    \"blaw201\": [\"blaw 201\", \"blaw-201\", \"businesslaw201\", \"business law 201\", \"business law i\"],\n",
        "    \"blaw202\": [\"blaw 202\", \"blaw-202\", \"businesslaw202\", \"business law 202\", \"business law ii\"],\n",
        "    \"blaw330\": [\"blaw 330\", \"blaw-330\", \"businesslaw330\", \"business law 330\", \"real estate law\"],\n",
        "    \"blaw346\": [\"blaw 346\", \"blaw-346\", \"businesslaw346\", \"business law 346\", \"entrepreneurial law\"],\n",
        "    \"blaw358\": [\"blaw 358\", \"blaw-358\", \"businesslaw358\", \"business law 358\", \"employment law\"],\n",
        "    \"blaw621\": [\"blaw 621\", \"blaw-621\", \"businesslaw621\", \"business law 621\", \"legal issues business\"],\n",
        "    \"mis\": [\"management systems\", \"management system\", \"business analytics\", \"introduction mis\", \"intro mis\"],\n",
        "    \"mis200\": [\"mis 200\", \"mis-200\", \"management information systems\"],\n",
        "    \"mis342\": [\"mis 342\", \"mis-342\", \"systems analysis and design\"],\n",
        "    \"mis343\": [\"mis 343\", \"mis-343\", \"database design and implementation\"],\n",
        "    \"mis346\": [\"mis 346\", \"mis-346\", \"management information systems strategy\"],\n",
        "    \"mis361\": [\"mis 361\", \"mis-361\", \"information system project management\"],\n",
        "    \"mis364\": [\"mis 364\", \"mis-364\", \"information security systems management\"],\n",
        "    \"mis612\": [\"mis 612\", \"mis-612\", \"aligning information systems and business strategies\"],\n",
        "    \"mis625\": [\"mis 625\", \"mis-625\", \"management information technology operations\"],\n",
        "    \"mis642\": [\"mis 642\", \"mis-642\", \"emerging information technologies business\"],\n",
        "    \"opm200\": [\"opm 200\", \"opm-200\", \"operations management\"],\n",
        "    \"opm324\": [\"opm 324\", \"opm-324\", \"operations planning\"],\n",
        "    \"opm342\": [\"opm 342\", \"opm-342\", \"sustainable supply chain management and logistics\"],\n",
        "    \"mktg201\": [\"mktg 201\", \"mktg-201\", \"introduction marketing management\"],\n",
        "    \"mktg322\": [\"mktg 322\", \"mktg-322\", \"advertising & integrated marketing communications\"],\n",
        "    \"mktg326\": [\"mktg 326\", \"mktg-326\", \"marketing insights\"],\n",
        "    \"mktg348\": [\"mktg 348\", \"mktg-348\", \"services marketing\"],\n",
        "    \"mktg356\": [\"mktg 356\", \"mktg-356\", \"consumer behavior\"],\n",
        "    \"mktg367\": [\"mktg 367\", \"mktg-367\", \"data-driven digital marketing\", \"digital marketing\"],\n",
        "    \"mktg368\": [\"mktg 368\", \"mktg-368\", \"corporate responsibility management\"],\n",
        "    \"mktg380\": [\"mktg 380\", \"mktg-380\", \"seminar marketing strategy\"],\n",
        "    \"mktg510\": [\"mktg 510\", \"mktg-510\", \"marketing strategy\"],\n",
        "    \"mktg601\": [\"mktg 601\", \"mktg-601\", \"marketing strategy & planning\"],\n",
        "    \"mktg607\": [\"mktg 607\", \"mktg-607\", \"marketing experiments\"],\n",
        "    \"mktg652\": [\"mktg 652\", \"mktg-652\", \"marketing information management and research\"],\n",
        "    \"mktg654\": [\"mktg 654\", \"mktg-654\", \"corporate brand & reputation management\"],\n",
        "    \"mktgt980\": [\"mktg t980\", \"mktg-t980\", \"perceptual processes consumer behavior\"],\n",
        "    \"mktg998\": [\"mktg 998\", \"mktg-998\", \"dissertation research marketing\"],\n",
        "    \"mgmt201\": [\"mgmt 201\", \"mgmt-201\", \"introduction technology innovation management\"],\n",
        "    \"mgmt260\": [\"mgmt 260\", \"mgmt-260\", \"introduction entrepreneurship\"],\n",
        "    \"mgmt240\": [\"mgmt 240\", \"mgmt-240\", \"mgmt 240\"],\n",
        "    \"mgmt301\": [\"mgmt 301\", \"mgmt-301\", \"designing innovative organizations\"],\n",
        "    \"mgmt302\": [\"mgmt 302\", \"mgmt-302\", \"competing technology industries\"],\n",
        "    \"mgmt364\": [\"mgmt 364\", \"mgmt-364\", \"technology management\"],\n",
        "    \"mgmt450\": [\"mgmt 450\", \"mgmt-450\", \"strategy and competitive advantage\"],\n",
        "    \"mgmt600\": [\"mgmt 600\", \"mgmt-600\", \"introduction change management\"],\n",
        "    \"mgmt603\": [\"mgmt 603\", \"mgmt-603\", \"technology strategy\"],\n",
        "    \"mgmt640\": [\"mgmt 640\", \"mgmt-640\", \"strategic human resource management\"],\n",
        "    \"mgmt770\": [\"mgmt 770\", \"mgmt-770\", \"mba capstone\"],\n",
        "    \"mgmt906\": [\"mgmt 906\", \"mgmt-906\", \"foundations research behavioral science\"],\n",
        "    \"mgmt935\": [\"mgmt 935\", \"mgmt-935\", \"seminar organization theory\"],\n",
        "    \"mgmt998\": [\"mgmt 998\", \"mgmt-998\", \"dissertation research management\"],\n",
        "    \"remd\": [\"real estate\", \"estate\"],\n",
        "    \"remd110\": [\"remd 110\", \"remd-110\", \"real estate management\", \"estate 110\", \"estate 110\"],\n",
        "    \"remd320\": [\"remd 320\", \"remd-320\", \"sustainability built environment\"],\n",
        "    \"remd375\": [\"remd 375\", \"remd-375\", \"real estate finance\"],\n",
        "    \"remd410\": [\"remd 410\", \"remd-410\", \"real estate investment and asset management\"],\n",
        "    \"cs171\": [\"cs 171\", \"cs-171\"],\n",
        "    \"cs150\": [\"cs 150\", \"cs-150\"],\n",
        "    \"engr\": [\"engineering cad\"],\n",
        "    \"engr113\": [\"engr 113\", \"engr-113\"],\n",
        "    \"com270\": [\"com 270\", \"com-270\"],\n",
        "    \"opr\": [\"operations\"],\n",
        "    \"opr320\": [\"opr 320\", \"opr-320\", \"linear models decision making\"],\n",
        "    \"opr601\": [\"opr 601\", \"opr-601\", \"managerial decision models and simulation\"],\n",
        "    \"opr998\": [\"opr 998\", \"opr-998\", \"dissertation research operations research\"],\n",
        "    \"busn101\": [\"busn 101\", \"busn-101\", \"foundations business i\"],\n",
        "    \"busn102\": [\"busn 102\", \"busn-102\", \"foundations business ii\"],\n",
        "    \"busn105\": [\"busn 105\", \"busn-105\", \"applied business analysis\"],\n",
        "    \"busn111\": [\"busn 111\", \"busn-111\", \"foundations business\"],\n",
        "    \"busn501\": [\"busn 501\", \"busn-501\", \"measuring and maximizing financial performance\"],\n",
        "    \"busn614\": [\"busn 614\", \"busn-614\", \"foundations career & professional development\"],\n",
        "    \"busn997\": [\"busn 997\", \"busn-997\", \"research activity phd students lebow college business\"],\n",
        "    \"bsan160\": [\"bsan 160\", \"bsan-160\", \"business analytics and data visualization\"],\n",
        "    \"bsan\": [\"business analytics\", \"analytic\", \"analytics\"],\n",
        "    \"bsan360\": [\"bsan 360\", \"bsan-360\", \"programming data analytics\"],\n",
        "    \"bsan460\": [\"bsan 460\", \"bsan-460\", \"business analytics senior project\"],\n",
        "    \"bsan601\": [\"bsan 601\", \"bsan-601\", \"business analytics managers\"],\n",
        "    \"bsan710\": [\"bsan 710\", \"bsan-710\", \"business analytics capstone project\"],\n",
        "    \"co-op\": [\"coop\"],\n",
        "    \"co-op101\": [\"co-op 101\", \"co-op-101\"],\n",
        "    \"orgb300\": [\"orgb 300\", \"orgb-300\", \"organizational behavior\"],\n",
        "    \"orgb430\": [\"orgb 430\", \"orgb-430\"],\n",
        "    \"orgb320\": [\"orgb 320\", \"orgb-320\", \"leadership: theory and practice\"],\n",
        "    \"orgb511\": [\"orgb 511\", \"orgb-511\", \"leading dynamic environments: personal, relational, and strategic approach\"],\n",
        "    \"intb200\": [\"intb 200\", \"intb-200\"],\n",
        "    \"econ202\": [\"econ 202\", \"econ-202\", \"introduction economics\"],\n",
        "    \"econ270\": [\"econ 270\", \"econ-270\", \"introduction macroeconomics\"],\n",
        "    \"econ321\": [\"econ 321\", \"econ-321\", \"microeconomics\"],\n",
        "    \"econ350\": [\"econ 350\", \"econ-350\", \"macroeconomics\"],\n",
        "    \"econ351\": [\"econ 351\", \"econ-351\", \"international economics\"],\n",
        "    \"econ352\": [\"econ 352\", \"econ-352\", \"financial economics\"],\n",
        "    \"econ353\": [\"econ 353\", \"econ-353\", \"international trade economics\"],\n",
        "    \"tax360\": [\"tax 360\", \"tax-360\"],\n",
        "    \"tax341\": [\"tax 341\", \"tax-341\"],\n",
        "    \"se181\": [\"se 181\", \"se-181\"],\n",
        "    \"accounting\": [\"accounting\", \"basic accounting\", \"financial accounting\", \"managerial accounting\",\n",
        "                   \"bookkeeping\", \"cash flows\", \"invoice\", \"accounting introduction\", \"internal audit\"],\n",
        "    \"finance\": [\"finance\", \"intro to finance\", \"financial planning\", \"investment management\",\n",
        "                \"corporate finance\", \"insurance\", \"financial reporting\", \"portfolio rebalancing\",\n",
        "                \"portfolio management\", \"financial markets\"],\n",
        "    \"economics\": [\"economics\", \"macroeconomics\", \"microeconomics\"],\n",
        "    \"mis200\": [\"mis200\", \"mis 200\", \"mis-200\"],\n",
        "    \"statistics\": [\"statistics\", \"basic statistics\", \"intro to stats\", \"statistical methods\", \"data statistics\", \"applied statistics\"],\n",
        "    \"python\": [\"python\", \"python programming\", \"python coding\", \"python scripting\"],\n",
        "    \"sql\": [\"sql\", \"structured query language\", \"sql programming\", \"database querying\"],\n",
        "    \"data_analysis\": [\"data analysis\", \"analyzing data\", \"data analytics\", \"data insights\", \"data visualization\"],\n",
        "    \"business_analytics\": [\"business analytics\", \"analytics for business\", \"business data analytics\", \"business intelligence\",\n",
        "                           \"projections\", \"kpis\", \"key performance indicators\"],\n",
        "    \"automation\": [\"automation\", \"intelligent automation tools\", \"workflow automation\", \"process automation\"],\n",
        "    \"leadership\": [\"leadership\", \"executive leadership\", \"project leadership\", \"team leadership\", \"organizational leadership\"],\n",
        "    \"tax\": [\"tax\", \"tax accounting\", \"tax planning\", \"tax strategies\"],\n",
        "    \"public_speaking\": [\"public speaking\", \"presentation skills\", \"oral communication\", \"speech delivery\", \"storytelling\"],\n",
        "    \"excel\": [\"excel\", \"microsoft excel\", \"advanced excel skills\", \"pivot tables\", \"vlookup\", \"data modeling\", \"spreadsheet\"],\n",
        "    \"powerpoint\": [\"powerpoint\", \"microsoft powerpoint\", \"presentation design\", \"slides creation\"],\n",
        "    \"marketing\": [\"marketing\", \"marketing strategies\", \"social media marketing\", \"advertising\", \"seo\", \"content marketing\"],\n",
        "    \"project_management\": [\"project management\", \"agile project management\", \"waterfall project management\", \"pmp\", \"scrum\"],\n",
        "    \"critical_thinking\": [\"critical thinking\", \"problem solving\", \"analytical thinking\", \"decision making\"],\n",
        "    \"data_visualization\": [\"data visualization\", \"chart creation\", \"dashboard creation\", \"data storytelling\", \"tableau\", \"power bi\"],\n",
        "    \"communication\": [\"communicate\", \"communication\", \"orator\", \"business communication\", \"written communication\", \"verbal communication\", \"busi-comm\"],\n",
        "    \"programming\": [\"programming\", \"coding\", \"software development\", \"scripting\"],\n",
        "    \"time_management\": [\"time management\", \"productivity skills\", \"scheduling\", \"prioritization\"],\n",
        "    \"crm\": [\"crm\", \"customer relationship management\", \"salesforce\", \"hubspot\", \"zoho crm\"],\n",
        "    \"ms_office\": [\"ms office\", \"microsoft office\", \"word\", \"outlook\"],\n",
        "    \"networking\": [\"networking\", \"professional networking\", \"relationship building\", \"linkedin\"],\n",
        "    \"entrepreneurship\": [\"entrepreneurship\", \"startup skills\", \"venture creation\", \"business innovation\"],\n",
        "    \"customer_service\": [\"customer service\", \"client relations\", \"service management\"],\n",
        "    \"supply_chain\": [\"supply chain\", \"logistics\", \"inventory management\", \"procurement\", \"supply chain analytics\"],\n",
        "    \"hr_management\": [\"hr management\", \"human resources\", \"recruitment\", \"talent management\", \"employee relations\"],\n",
        "    \"cybersecurity\": [\"cybersecurity\", \"information security\", \"network security\", \"data security\", \"ethical hacking\"],\n",
        "    \"soft_skills\": [\"soft skills\", \"speaking\", \"technical communication\", \"presentation\"],\n",
        "    \"sales\": [\"sales\", \"selling\"],\n",
        "    \"technical_skills\": [\"technical skills\", \"reporting\", \"tracking\", \"trading\", \"planning\", \"forecasting\", \"graphic design\"],\n",
        "    \"syst_anal\": [\"systems analysis\", \"system analysis\"],\n",
        "    \"business\": [\"business\", \"organizational\", \"elementary business\"],\n",
        "    \"hospitality\": [\"hospitality\", \"beverages\"],\n",
        "    \"preliminary\": [\"preliminary\"],\n",
        "    \"advanced\": [\"advanced\"],\n",
        "    \"digital marketing\": [\"digital marketing\", \"social media marketing\"],\n",
        "    \"writing_skills\": [\"writing skills\", \"email\", \"e-mails\", \"writing\", \"written\", \"writer\", \"write\"],\n",
        "    \"prioritization\": [\"prioritization\", \"priority\"],\n",
        "    \"projects\": [\"projects\", \"team project\", \"project\", \"team projects\", \"teamwork\", \"group projects\", \"collaboration\", \"team\"],\n",
        "    \"MIS\": [\"MIS\", \"management information systems\", \"mis\"],\n",
        "    \"data_analytics\": [\"data analytics\", \"data analysis\", \"analytics\"],\n",
        "    \"regression\": [\"regression\", \"linear regression\", \"logistic regression\"],\n",
        "    \"operations_management\": [\"operations management\", \"supply chain\", \"operations\"],\n",
        "    \"self_taught\": [\"personal\", \"self\", \"taught\", 'yourself', 'ourselves', \"yourselves\", \"self-taught\", \"own\", \"myself\", \"learn\", \"ask\", \"asked\"],\n",
        "    \"prior_work_experience\": [\"prior\", \"previous\"],\n",
        "    \"during_coop\": [\"during\", \"co-op\", \"job\", \"role\"],\n",
        "    \"problem_solving\": [\"problem\", \"solving\", \"problem-solving\"],\n",
        "    \"classroom_activities\": [\"classroom activities\", \"class\", \"classroom\", \"involved\", \"interactive\", \"participation\", \"interactivity\"]\n",
        "\n",
        "}\n",
        "\n",
        "# Match keywords from the synonym library\n",
        "def match_keywords(text, synonym_lib):\n",
        "    matched_courses = []\n",
        "    for course, keywords in synonym_lib.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                matched_courses.append(course)\n",
        "    return matched_courses\n",
        "\n",
        "# Function to remove repetitive words while preserving the order\n",
        "def remove_repeated_words(text_list):\n",
        "    seen = set()\n",
        "    distinct_words = []\n",
        "    for word in text_list:  # Iterate through the list of words directly\n",
        "        if word not in seen:\n",
        "            seen.add(word)\n",
        "            distinct_words.append(word)\n",
        "    return ' '.join(distinct_words)\n",
        "\n",
        "# Analyze text for relevant courses and classify responses\n",
        "def analyze_text(df, synonym_lib):\n",
        "    df['Cleaned_Text'] = df['How did your classroom activities prepare you for co-op? If they didn’t, how were you prepared for co-op?'].apply(preprocess_text)\n",
        "    df['Matched_Courses'] = df['Cleaned_Text'].apply(lambda x: match_keywords(x, synonym_lib))\n",
        "    df['Classification'] = df['How did your classroom activities prepare you for co-op? If they didn’t, how were you prepared for co-op?'].apply(classify_response)\n",
        "    return df\n",
        "\n",
        "# Process the data\n",
        "df = analyze_text(df, synonym_library)\n",
        "\n",
        "# Apply the function to remove repeated words in the 'Matched_Courses' column\n",
        "df['Distinct_Response'] = df['Matched_Courses'].apply(remove_repeated_words)\n",
        "\n",
        "# Create binary columns for synonym library matches\n",
        "def add_binary_columns(df, synonym_lib):\n",
        "    for course, keywords in synonym_lib.items():\n",
        "        df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
        "    return df\n",
        "\n",
        "# Add \"Others\" column\n",
        "def add_others_column(df, synonym_lib):\n",
        "    keyword_columns = list(synonym_lib.keys())\n",
        "    # Add the \"Others\" column\n",
        "    df['Others'] = df[keyword_columns].sum(axis=1).apply(lambda x: 1 if x == 0 else 0)\n",
        "    return df\n",
        "\n",
        "# Process the data\n",
        "df = analyze_text(df, synonym_library)\n",
        "\n",
        "# Add binary columns for matched courses\n",
        "df = add_binary_columns(df, synonym_library)\n",
        "\n",
        "# Add the \"Others\" column\n",
        "df = add_others_column(df, synonym_library)\n",
        "\n",
        "# Explode matched courses into separate rows for Power BI\n",
        "df_exploded = df.explode('Matched_Courses')\n",
        "\n",
        "# Save the results to an Excel file\n",
        "df.to_excel(\"processed_responses_with_classification_and_others_column.xlsx\", index=False)\n",
        "\n",
        "print(\"Processing completed and results saved with binary columns and 'Others' column!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuPT9VVZgzDS",
        "outputId": "dfeb8bcb-b636-49f3-ba24-0d7a687e4d69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:290: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[course] = df['Cleaned_Text'].apply(lambda text: 1 if any(keyword in text for keyword in keywords) else 0)\n",
            "<ipython-input-1-e3f6281d7f0d>:297: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['Others'] = df[keyword_columns].sum(axis=1).apply(lambda x: 1 if x == 0 else 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing completed and results saved with binary columns and 'Others' column!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords resource (only needs to be run once)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the stopwords\n",
        "stop_words_list = set(stopwords.words('english'))\n",
        "\n",
        "# Download and initialize NLTK resources if needed\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(\"/content/what coursework did you apply most during your coop.xlsx\")  # Update the file path as needed\n",
        "\n",
        "# Text cleaning function to remove punctuation and stop words\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase and handle non-string values\n",
        "    text = str(text).lower()\n",
        "    # Remove parentheses but keep their content\n",
        "    text = re.sub(r'\\((.*?)\\)', r'\\1', text)\n",
        "    # Remove punctuation except hyphens\n",
        "    text = re.sub(r'(?<![a-zA-Z0-9-])[^\\w\\s,.-](?![a-zA-Z0-9-])', '', text)\n",
        "    text = re.sub(r'[.,]', '', text)\n",
        "    # Remove 'x000D' and similar artifacts\n",
        "    text = re.sub(r'_x[0-9a-fA-F]{4}_', '', text)  # Matches patterns like 'x000D'\n",
        "    # Remove stop words\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "# Define stop words, including custom additions\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stop_words = {\"i\", \"my\", \"course\", \"lebow\", \"would\", \"say\", \"class\", \"course\", \"courses\", \"class\", \"classes\", \"univ\", \"university\",\n",
        "    \"college\", \"lebow\", \"drexel\", \"major\", \"school\", \"student\", \"involved\", \"group --\", \"important\", \"everyday\", \"basis\",\n",
        "    \"topic\", \"topics\", \"assignment\", \"assignments\", \"lesson\", \"material\", \"program\",\n",
        "    \"prepare\", \"prepared\", \"apply\", \"applied\", \"using\", \"use\", \"learn\", \"learned\",\n",
        "    \"knowledge\", \"skills\", \"help\", \"helped\", \"helpful\", \"benefit\", \"benefited\",\n",
        "    \"during\", \"most\", \"best\", \"thing\", \"things\", \"one\", \"lot\", \"lots\", \"much\", \"many\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
        "    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\",\n",
        "    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"complaint\", \"letters\", \"city\", \"philadelphia\", \"customer's\", \"insurance\", \"claims\", \"surprisingly\",\n",
        "    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\",\n",
        "    \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"played\", \"large\", \"role\", \"expected\", \"type\", \"concise\", \"e-mails\", \"co-workers\", \"generate\", \"reports\", \"progress\", \"duties\", \"dealt\", \"erps\", \"cigna\", \"utilized\", \"oracle\", \"database\", \"ariba\", \"invoicing\", \"payment\", \"software\",\n",
        "    \"did\", \"doing\", \"a\", \"an\", \"concept\", \"staking\", \"general\", \"venue\",  \"prior\", \"utilize\", \"search\", \"servicing\", \"provided\", \"great\", \"amount\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\",\n",
        "    \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n",
        "    \"through\", \"during\", \"before\", \"after\", \"given\", \"perspective\", \"above\", \"below\", \"from\", \"up\", \"down\",\n",
        "    \"in\", \"out\", \"on\", \"probably\", \"part\", \"contain\", \"aspects\", \"may\", \"principles\", \"applicable\", \"yet\", \"skill\", \"problem\", \"solving\", \"become\", \"illustrator\", \"successful\", \"roles\", \"required\", \"team\", \"setting\", \"often\", \"able\", \"working\", \"attorneys\", \"promotional\", \"products\", \"events\", \"also\", \"effectively\", \"communicate\", \"adhere\", \"corporate\", \"successfully\", \"according\", \"multiple\", \"supervisors\", \"hope\", \"future\",\n",
        "    \"captions\", \"social\", \"media\", \"accounts\", \"interaction\", \"whether\", \"finances\", \"going\", \"logistics\", \"reflected\", \"well\", \"although\", \"day-to-day\", \"understanding\", \"hit\", \"ground\", \"running\", \"didn’t\",\n",
        "     \"off\", \"over\", \"relied\", \"past\", \"under\", \"again\", \"further\", \"then\", \"once\",\n",
        "    \"consulting\", \"peer\", \"leader\", \"practicum\", \"development\", \"leadership\", \"people\", \"honors\", \"projects\", \"timezones\", \"background\", \"tech\", \"processes\", \"created\", \"familiarity\", \"technological\", \"responsibilities\", \"knowing\", \"verbiage\", \"formatting\", \"professional\", \"conversations\", \"helping\", \"accomplish\",\n",
        "    \"here\", \"there\", \"when\", \"where\", \"critical\", \"thinking\", \"think\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
        "    \"referenced\", \"various\", \"knew\", \"like\", \"improve\", \"early\", \"guess\", \"adobe\", \"suite\", \"extra\", \"cirrculars\", \"professionalism\", \"emails\", \"meetings\", \"etc\", \"academic\", \"random\", \"number\", \"generators\", \"sampling\",\n",
        "    \"few\", \"more\", \"most\", \"took\", \"event\", \"facilities\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\",\n",
        "    \"own\", \"same\", \"so\", \"than\", \"projects\", \"people\", \"different\", \"timezones\", \"too\", \"very\", \"understand\", \"language\", \"trust\", \"s\", \"t\", \"can\", \"will\", \"just\", \"intermediate\",\n",
        "    \"don\", \"should\", \"now\", \"used\", \"mostly\", \"since\", \"files\", \",\", \"terms\", \"super\", \"familiar\", \"base\", \"expanded\", \"manager\", \"coworkers\",\n",
        "    \"work\", \"i've\", \"coursework\", \"relevant\", \"people\", \"nan\", \"coworkers\", \"carried\", \"bulk\", \"information\", \"needed\", \"felt\", \"properly\", \"believe\", \"useful\",\n",
        "    \"far\", \"career\", \"path\", \"everything\", \"ii\", \"loan\", \"literally\", \"least\", \"every\", \"better\", \"company\", \"job\",\n",
        "    \"sure\", \"prep\", \"world\", \"ideas\", \"create\", \"proficient\", \"generally\", \"specifically\", \"certain\", \"prof\", \"cohen\", \"huge\",\n",
        "    \"ticketing\", \"department\", \"taught\", \"crm\", \"made\", \"easier\", \"handle\", \"score\", \"next\", \"daily\", \"lastly\", \"another\", \"comes\", \"don’t\", \"realize\", \"go\", \"executing\", \"moving\", \"parts\", \"got\", \"overwhelmed\", \"appreciated\", \"leaned\", \"put\", \"game\", \"day\", \"weeks\", \"end\", \"benefitted\", \"obviously\", \"grateful\", \"i’ve\", \"thus\",\n",
        "    \"interesting\", \"see\", \"real\", \"world\", \"directly\", \"none\", \"related\", \"come\", \"mind\", \"developed\", \"throughout\", \"previous\", \"taken\",\n",
        "    \"intro\", \"honestly\", \"really\", \"teach\", \"*honors\", \"imperative\", \"minor\", \"cib\", \"teach\", \"write\", \"reading\", \"statements\", \"writing\", \"data\", \"goes\", \"formulas\", \"behind\", \"desks\", \"interesting\", \"nothing\", \"even\", \"specific\", \"mainly\", \"came\", \"handy\", \"position\", \"quite\",\n",
        "    \"salesperson\", \"get\", \"license\", \"photoshop\", \"reasoning\", \"teaches\", \"ethical\", \"rules\", \"abide\", \"order\", \"basic\", \"honors\", \"shoutout\", \"dana\", \"d'angelo\", \"consisted\", \"artificial\", \"technology\", \"metaverse\", \"absolutely\", \"opinion\", \"take\", \"experience\", \"lectures\", \"learning\", \"unnecessary\", \"good\", \"exam\", \"forget\", \"right\", \"finished\",\n",
        "\n",
        "                     }  # Custom stop words to remove\n",
        "\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "\n",
        "# Clean text column\n",
        "df['Cleaned_Response'] = df['What coursework did you apply most during your co-op?'].apply(clean_text)\n",
        "\n",
        "# Define a synonym library to standardize course names\n",
        "synonym_library = {\n",
        "    \"introduction\": [\"intro\"],\n",
        "    \"acct116\": [\"acct 116\", \"acct-116\", \"accounting 116\", \"managerial accounting\"],\n",
        "    \"acct115\": [\"acct 115\", \"acct-115\", \"accounting 115\", \"financial accounting\"],\n",
        "    \"acct110\": [\"acct 110\", \"acct-110\", \"accounting 110\", \"accounting for professionals\"],\n",
        "    \"acct321\": [\"acct 321\", \"acct-321\", \"accounting321\", \"accounting 321\", \"financial reporting i\"],\n",
        "    \"acct323\": [\"acct 323\", \"acct-323\", \"accounting323\", \"accounting 323\", \"financial reporting iii\"],\n",
        "    \"acct329\": [\"acct 329\", \"acct-329\", \"accounting329\", \"accounting 329\", \"advanced accounting\"],\n",
        "    \"acct341\": [\"acct 341\", \"acct-341\", \"accounting341\", \"accounting 341\", \"principles auditing\"],\n",
        "    \"acct510\": [\"acct 510\", \"acct-510\", \"accounting510\", \"accounting 510\", \"essentials financial reporting\"],\n",
        "    \"acct600\": [\"acct 600\", \"acct-600\", \"accounting600\", \"accounting 600\", \"accounting analysis & theory\"],\n",
        "    \"acct606\": [\"acct 606\", \"acct-606\", \"accounting606\", \"accounting 606\", \"current issues accounting profession\"],\n",
        "    \"acct622\": [\"acct 622\", \"acct-622\", \"accounting622\", \"accounting 622\", \"advanced financial accounting\"],\n",
        "    \"acct912\": [\"acct 912\", \"acct-912\", \"accounting912\", \"accounting 912\", \"applied research methods accounting\"],\n",
        "    \"acct998\": [\"acct 998\", \"acct-998\", \"accounting998\", \"accounting 998\", \"dissertation research accounting\"],\n",
        "    \"stat201\": [\"stat 201\", \"stat-201\", \"statistics201\", \"statistics 201\", \"introduction business statistics\", \"business statistics i\"],\n",
        "    \"stat202\": [\"stat 202\", \"stat-202\", \"statistics202\", \"statistics 202\", \"business statistics ii\"],\n",
        "    \"stat205\": [\"stat 205\", \"stat-205\", \"statistics205\", \"statistics 205\", \"statistical inference i\"],\n",
        "    \"stat331\": [\"stat 331\", \"stat-331\", \"statistics331\", \"statistics 331\", \"introduction data mining business\"],\n",
        "    \"stat610\": [\"stat 610\", \"stat-610\", \"statistics610\", \"statistics 610\", \"statistics business analytics\"],\n",
        "    \"stat628\": [\"stat 628\", \"stat-628\", \"statistics628\", \"statistics 628\", \"applied regression analysis\"],\n",
        "    \"stat931\": [\"stat 931\", \"stat-931\", \"statistics931\", \"statistics 931\", \"statistics economics\"],\n",
        "    \"stat932\": [\"stat 932\", \"stat-932\", \"statistics932\", \"statistics 932\", \"statistics behavioral science\"],\n",
        "    \"fin301\": [\"fin 301\", \"fin-301\", \"finance301\", \"finance 301\", \"introduction finance\"],\n",
        "    \"fin302\": [\"fin 302\", \"fin-302\", \"finance302\", \"finance 302\", \"intermediate corporate finance\"],\n",
        "    \"fin321\": [\"fin 321\", \"fin-321\", \"finance321\", \"finance 321\", \"investment securities & markets\"],\n",
        "    \"fin323\": [\"fin 323\", \"fin-323\", \"finance323\", \"finance 323\", \"risk management\"],\n",
        "    \"fin325\": [\"fin 325\", \"fin-325\", \"finance325\", \"finance 325\", \"financial institutions and markets\"],\n",
        "    \"fin332\": [\"fin 332\", \"fin-332\", \"finance332\", \"finance 332\", \"investment analysis\"],\n",
        "    \"fin335\": [\"fin 335\", \"fin-335\", \"finance335\", \"finance 335\", \"entrepreneurial finance\"],\n",
        "    \"fin341\": [\"fin 341\", \"fin-341\", \"finance341\", \"finance 341\", \"applied portfolio management\"],\n",
        "    \"fin345\": [\"fin 345\", \"fin-345\", \"finance345\", \"finance 345\", \"mergers & acquisitions\"],\n",
        "    \"fin346\": [\"fin 346\", \"fin-346\", \"finance346\", \"finance 346\", \"global financial management\"],\n",
        "    \"fin601\": [\"fin 601\", \"fin-601\", \"finance601\", \"finance 601\", \"corporate financial management\"],\n",
        "    \"fin605\": [\"fin 605\", \"fin-605\", \"finance605\", \"finance 605\", \"business valuation\"],\n",
        "    \"fin624\": [\"fin 624\", \"fin-624\", \"finance624\", \"finance 624\", \"risk management financial professionals\"],\n",
        "    \"blaw\": [\"business law\"],\n",
        "    \"blaw101\": [\"blaw 101\", \"blaw-101\", \"businesslaw101\", \"business law 101\"],\n",
        "    \"blaw201\": [\"blaw 201\", \"blaw-201\", \"businesslaw201\", \"business law 201\", \"business law i\"],\n",
        "    \"blaw202\": [\"blaw 202\", \"blaw-202\", \"businesslaw202\", \"business law 202\", \"business law ii\"],\n",
        "    \"blaw330\": [\"blaw 330\", \"blaw-330\", \"businesslaw330\", \"business law 330\", \"real estate law\"],\n",
        "    \"blaw346\": [\"blaw 346\", \"blaw-346\", \"businesslaw346\", \"business law 346\", \"entrepreneurial law\"],\n",
        "    \"blaw358\": [\"blaw 358\", \"blaw-358\", \"businesslaw358\", \"business law 358\", \"employment law\"],\n",
        "    \"blaw621\": [\"blaw 621\", \"blaw-621\", \"businesslaw621\", \"business law 621\", \"legal issues business\"],\n",
        "    \"mis\": [\"management systems\", \"management system\", \"business analytics\"],\n",
        "    \"mis200\": [\"mis 200\", \"mis-200\", \"management information systems\"],\n",
        "    \"mis342\": [\"mis 342\", \"mis-342\", \"systems analysis and design\"],\n",
        "    \"mis343\": [\"mis 343\", \"mis-343\", \"database design and implementation\"],\n",
        "    \"mis346\": [\"mis 346\", \"mis-346\", \"management information systems strategy\"],\n",
        "    \"mis361\": [\"mis 361\", \"mis-361\", \"information system project management\"],\n",
        "    \"mis364\": [\"mis 364\", \"mis-364\", \"information security systems management\"],\n",
        "    \"mis612\": [\"mis 612\", \"mis-612\", \"aligning information systems and business strategies\"],\n",
        "    \"mis625\": [\"mis 625\", \"mis-625\", \"management information technology operations\"],\n",
        "    \"mis642\": [\"mis 642\", \"mis-642\", \"emerging information technologies business\"],\n",
        "    \"opm200\": [\"opm 200\", \"opm-200\", \"operations management\"],\n",
        "    \"opm324\": [\"opm 324\", \"opm-324\", \"operations planning\"],\n",
        "    \"opm342\": [\"opm 342\", \"opm-342\", \"sustainable supply chain management and logistics\"],\n",
        "    \"mktg201\": [\"mktg 201\", \"mktg-201\", \"introduction marketing management\"],\n",
        "    \"mktg322\": [\"mktg 322\", \"mktg-322\", \"advertising & integrated marketing communications\"],\n",
        "    \"mktg326\": [\"mktg 326\", \"mktg-326\", \"marketing insights\"],\n",
        "    \"mktg348\": [\"mktg 348\", \"mktg-348\", \"services marketing\"],\n",
        "    \"mktg356\": [\"mktg 356\", \"mktg-356\", \"consumer behavior\"],\n",
        "    \"mktg367\": [\"mktg 367\", \"mktg-367\", \"data-driven digital marketing\", \"digital marketing\"],\n",
        "    \"mktg368\": [\"mktg 368\", \"mktg-368\", \"corporate responsibility management\"],\n",
        "    \"mktg380\": [\"mktg 380\", \"mktg-380\", \"seminar marketing strategy\"],\n",
        "    \"mktg510\": [\"mktg 510\", \"mktg-510\", \"marketing strategy\"],\n",
        "    \"mktg601\": [\"mktg 601\", \"mktg-601\", \"marketing strategy & planning\"],\n",
        "    \"mktg607\": [\"mktg 607\", \"mktg-607\", \"marketing experiments\"],\n",
        "    \"mktg652\": [\"mktg 652\", \"mktg-652\", \"marketing information management and research\"],\n",
        "    \"mktg654\": [\"mktg 654\", \"mktg-654\", \"corporate brand & reputation management\"],\n",
        "    \"mktgt980\": [\"mktg t980\", \"mktg-t980\", \"perceptual processes consumer behavior\"],\n",
        "    \"mktg998\": [\"mktg 998\", \"mktg-998\", \"dissertation research marketing\"],\n",
        "    \"mgmt201\": [\"mgmt 201\", \"mgmt-201\", \"introduction technology innovation management\"],\n",
        "    \"mgmt260\": [\"mgmt 260\", \"mgmt-260\", \"introduction entrepreneurship\"],\n",
        "    \"mgmt240\": [\"mgmt 240\", \"mgmt-240\", \"mgmt 240\"],\n",
        "    \"mgmt301\": [\"mgmt 301\", \"mgmt-301\", \"designing innovative organizations\"],\n",
        "    \"mgmt302\": [\"mgmt 302\", \"mgmt-302\", \"competing technology industries\"],\n",
        "    \"mgmt364\": [\"mgmt 364\", \"mgmt-364\", \"technology management\"],\n",
        "    \"mgmt450\": [\"mgmt 450\", \"mgmt-450\", \"strategy and competitive advantage\"],\n",
        "    \"mgmt600\": [\"mgmt 600\", \"mgmt-600\", \"introduction change management\"],\n",
        "    \"mgmt603\": [\"mgmt 603\", \"mgmt-603\", \"technology strategy\"],\n",
        "    \"mgmt640\": [\"mgmt 640\", \"mgmt-640\", \"strategic human resource management\"],\n",
        "    \"mgmt770\": [\"mgmt 770\", \"mgmt-770\", \"mba capstone\"],\n",
        "    \"mgmt906\": [\"mgmt 906\", \"mgmt-906\", \"foundations research behavioral science\"],\n",
        "    \"mgmt935\": [\"mgmt 935\", \"mgmt-935\", \"seminar organization theory\"],\n",
        "    \"mgmt998\": [\"mgmt 998\", \"mgmt-998\", \"dissertation research management\"],\n",
        "    \"remd\": [\"real estate\", \"estate\"],\n",
        "    \"remd110\": [\"remd 110\", \"remd-110\", \"real estate management\", \"estate 110\", \"estate 110\"],\n",
        "    \"remd320\": [\"remd 320\", \"remd-320\", \"sustainability built environment\"],\n",
        "    \"remd375\": [\"remd 375\", \"remd-375\", \"real estate finance\"],\n",
        "    \"remd410\": [\"remd 410\", \"remd-410\", \"real estate investment and asset management\"],\n",
        "    \"cs171\": [\"cs 171\", \"cs-171\"],\n",
        "    \"cs150\": [\"cs 150\", \"cs-150\"],\n",
        "    \"engr\": [\"engineering cad\"],\n",
        "    \"engr113\": [\"engr 113\", \"engr-113\"],\n",
        "    \"com270\": [\"com 270\", \"com-270\"],\n",
        "    \"opr\": [\"operations\"],\n",
        "    \"opr320\": [\"opr 320\", \"opr-320\", \"linear models decision making\"],\n",
        "    \"opr601\": [\"opr 601\", \"opr-601\", \"managerial decision models and simulation\"],\n",
        "    \"opr998\": [\"opr 998\", \"opr-998\", \"dissertation research operations research\"],\n",
        "    \"busn101\": [\"busn 101\", \"busn-101\", \"foundations business i\"],\n",
        "    \"busn102\": [\"busn 102\", \"busn-102\", \"foundations business ii\"],\n",
        "    \"busn105\": [\"busn 105\", \"busn-105\", \"applied business analysis\"],\n",
        "    \"busn111\": [\"busn 111\", \"busn-111\", \"foundations business\"],\n",
        "    \"busn501\": [\"busn 501\", \"busn-501\", \"measuring and maximizing financial performance\"],\n",
        "    \"busn614\": [\"busn 614\", \"busn-614\", \"foundations career & professional development\"],\n",
        "    \"busn997\": [\"busn 997\", \"busn-997\", \"research activity phd students lebow college business\"],\n",
        "    \"bsan160\": [\"bsan 160\", \"bsan-160\", \"business analytics and data visualization\"],\n",
        "    \"bsan360\": [\"bsan 360\", \"bsan-360\", \"programming data analytics\"],\n",
        "    \"bsan460\": [\"bsan 460\", \"bsan-460\", \"business analytics senior project\"],\n",
        "    \"bsan601\": [\"bsan 601\", \"bsan-601\", \"business analytics managers\"],\n",
        "    \"bsan710\": [\"bsan 710\", \"bsan-710\", \"business analytics capstone project\"],\n",
        "    \"co-op\": [\"coop\"],\n",
        "    \"co-op101\": [\"co-op 101\", \"co-op-101\"],\n",
        "    \"orgb300\": [\"orgb 300\", \"orgb-300\", \"organizational behavior\"],\n",
        "    \"orgb320\": [\"orgb 320\", \"orgb-320\", \"leadership: theory and practice\"],\n",
        "    \"orgb511\": [\"orgb 511\", \"orgb-511\", \"leading dynamic environments: personal, relational, and strategic approach\"],\n",
        "    \"intb200\": [\"intb 200\", \"intb-200\"],\n",
        "    \"econ202\": [\"econ 202\", \"econ-202\", \"introduction economics\"],\n",
        "    \"econ270\": [\"econ 270\", \"econ-270\", \"introduction macroeconomics\"],\n",
        "    \"econ321\": [\"econ 321\", \"econ-321\", \"microeconomics\"],\n",
        "    \"econ350\": [\"econ 350\", \"econ-350\", \"macroeconomics\"],\n",
        "    \"econ351\": [\"econ 351\", \"econ-351\", \"international economics\"],\n",
        "    \"econ352\": [\"econ 352\", \"econ-352\", \"financial economics\"],\n",
        "    \"econ353\": [\"econ 353\", \"econ-353\", \"international trade economics\"],\n",
        "    \"tax360\": [\"tax 360\", \"tax-360\"],\n",
        "    \"tax341\": [\"tax 341\", \"tax-341\"],\n",
        "    \"se181\": [\"se 181\", \"se-181\"],\n",
        "    \"accounting\": [\"bookkeeping\", \"cash flows\", \"invoice\", \"invoices\"],\n",
        "    \"business101\": [\"business 101\", \"business-101\"],\n",
        "    \"business102\": [\"business 102\", \"business-102\"],\n",
        "    \"engl\": [\"english\"],\n",
        "    \"finance\": [\"financial\", \"financial reporting\", \"financial analysis\", \"portfolio rebalancing\", \"portfolio management\", \"financial markets\"],\n",
        "    \"soft-skills\": [\"speaking\", \"speak\", \"technical communication\", \"time management\", \"presentation\", \"presentations\"],\n",
        "    \"sales\": [\"sales\", \"selling\", \"sale\", \"selling\"],\n",
        "    \"technical-skills\": [\"excel\", \"spreadsheet\", \"email\", \"reporting\", \"powerpoint\", \"trading\", \"planning\", \"forecasting\", \"graphic design\"],\n",
        "    \"busi-comm\": [\"business communication\", \"business communications\"]\n",
        "}\n",
        "\n",
        "\n",
        "# Function to standardize keywords based on the synonym library\n",
        "def standardize_keywords(text, synonym_lib):\n",
        "    for standard_term, synonyms in synonym_lib.items():\n",
        "        for synonym in synonyms:\n",
        "            text = re.sub(rf\"\\b{re.escape(synonym)}\\b\", standard_term, text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "# Function to expand course codes like \"business 101 102\" to \"business 101 business 102\"\n",
        "def expand_course_codes(text):\n",
        "    words = text.split()  # Split the input string into words\n",
        "    if len(words) > 2:  # Ensure there's something to expand\n",
        "        prefix = words[0]\n",
        "        numbers = words[1:]\n",
        "        expanded = [f\"{prefix} {number}\" for number in numbers]\n",
        "        return \" \".join(expanded)\n",
        "    return text  # Return unchanged if there's nothing to expand\n",
        "\n",
        "# # Apply keyword standardization\n",
        "df['Standardized_Response'] = df['Cleaned_Response'].apply(lambda x: standardize_keywords(x, synonym_library))\n",
        "\n",
        "# Function to remove repetitive words while preserving the order\n",
        "def remove_repeated_words(text):\n",
        "    words = text.split()\n",
        "    seen = set()\n",
        "    distinct_words = []\n",
        "    for word in words:\n",
        "        if word not in seen:\n",
        "            seen.add(word)\n",
        "            distinct_words.append(word)\n",
        "    return ' '.join(distinct_words)\n",
        "\n",
        "# Apply the function to remove repeated words in the 'Standardized_Response' column\n",
        "df['Distinct_Response'] = df['Standardized_Response'].apply(remove_repeated_words)\n",
        "\n",
        "# Function to add binary columns for synonym library matches\n",
        "def add_binary_columns(df, synonym_lib):\n",
        "    for standard_term, synonyms in synonym_lib.items():\n",
        "        df[standard_term] = df['Standardized_Response'].apply(\n",
        "            lambda text: 1 if any(keyword in text for keyword in synonyms) else 0\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# Add an \"Others\" column\n",
        "def add_others_column(df, synonym_lib):\n",
        "    binary_columns = list(synonym_lib.keys())\n",
        "    # Add \"Others\" column, where no other binary columns are 1\n",
        "    df['Others'] = df[binary_columns].sum(axis=1).apply(lambda x: 1 if x == 0 else 0)\n",
        "    return df\n",
        "\n",
        "# Apply keyword standardization\n",
        "df['Standardized_Response'] = df['Cleaned_Response'].apply(lambda x: standardize_keywords(x, synonym_library))\n",
        "\n",
        "# Add binary columns based on the synonym library\n",
        "df = add_binary_columns(df, synonym_library)\n",
        "\n",
        "# Add the \"Others\" column\n",
        "df = add_others_column(df, synonym_library)\n",
        "\n",
        "# Save the processed DataFrame to an Excel file\n",
        "df.to_excel(\"relevant_courses_with_binary_and_others.xlsx\", index=False)\n",
        "\n",
        "print(\"Processing completed and results saved with binary columns and 'Others' column!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f6mlwURiU7z",
        "outputId": "bd287a4d-d219-454b-b752-879dbdcd2802"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[standard_term] = df['Standardized_Response'].apply(\n",
            "<ipython-input-3-e4dfd3053064>:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['Others'] = df[binary_columns].sum(axis=1).apply(lambda x: 1 if x == 0 else 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing completed and results saved with binary columns and 'Others' column!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "keOfBLhsg7jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}